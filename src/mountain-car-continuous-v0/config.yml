run:
  file_dir: "temp/v17"

env:
  name: MountainCarContinuous-v0
  max_step: 200

value:
  skip: false
  n_warmup_sim: 0  # 200000
  max_pos_episodes: null # Optional[int]
  at_most_n_neg_episodes_per_pos: 10 # Optional[float]
  reward:
    max_vel_weight: 1.
    min_vel_weight: 0.25
    max_dist_weight: 0.5
    min_dist_weight: 0.125
    discount: 0.0
    end_reward_scale: 100. # 100.
    step_reward_scale: 0. # 1.0
    all_steps_have_end_value: true
  load_dataset: false
  exploration:
    constant: 0.5
    step_factor: 0.5  # Optional[float]
  val_split: 0.1
  n_incremental_step: 20
  n_incremental_sim: 10000
  n_sim_in_batch: 10000
  extreme_action_chance:
    constant: 1.0
    step_factor: 0.5  # Optional[float]
  epochs: 100
  model:
    load: true
    layers:
      - type: dense
        units: 8
        activation: relu
      - type: dense
        units: 8
        activation: relu
      - type: dense
        units: 4
        activation: relu
      - type: dense
        units: 1
        activation: linear
  lr: 1.e-4
  min_delta: 1.e-7
  monitor: val_loss
  label_scale: 1.e-2
  batch_size: 50
  initial_score: false
  score_period: 10

policy:
  skip: false
  n_sim: 100
  n_policy_samples: 20000
  n_action_samples: 20
  load_dataset: false
  epochs: 10000
  lr: 1.e-4
  min_delta: 1.e-5
  monitor: loss
  batch_size: 50
  score_period: 10

eval:
  n_sim: 5
  render_every_n_step: null # Optional[int]

